{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "import mlflow.sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>I love Umberto Lenzi's cop movies -- ROME ARME...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>Oh my lord, what were they thinking about with...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>Emma is a horribly flawed film based on Jane A...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>Over the years I've watched this movie many ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>I don't understand the low 5.7 rating on this ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                review sentiment\n",
       "243  I love Umberto Lenzi's cop movies -- ROME ARME...  negative\n",
       "955  Oh my lord, what were they thinking about with...  negative\n",
       "596  Emma is a horribly flawed film based on Jane A...  positive\n",
       "777  Over the years I've watched this movie many ti...  positive\n",
       "709  I don't understand the low 5.7 rating on this ...  positive"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('IMDB.csv')\n",
    "df = df.sample(500)\n",
    "df.to_csv('data.csv', index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/manavdesai/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/manavdesai/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/manavdesai/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')     # For lemmatizer\n",
    "nltk.download('omw-1.4')     # Optional, but helps with WordNet\n",
    "nltk.download('stopwords')   # Since you're using stopwords too\n",
    "\n",
    "# data preprocessing\n",
    "\n",
    "# Define text preprocessing functions\n",
    "def lemmatization(text):\n",
    "    \"\"\"Lemmatize the text.\"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = text.split()\n",
    "    text = [lemmatizer.lemmatize(word) for word in text]\n",
    "    return \" \".join(text)\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    \"\"\"Remove stop words from the text.\"\"\"\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    text = [word for word in str(text).split() if word not in stop_words]\n",
    "    return \" \".join(text)\n",
    "\n",
    "def removing_numbers(text):\n",
    "    \"\"\"Remove numbers from the text.\"\"\"\n",
    "    text = ''.join([char for char in text if not char.isdigit()])\n",
    "    return text\n",
    "\n",
    "def lower_case(text):\n",
    "    \"\"\"Convert text to lower case.\"\"\"\n",
    "    text = text.split()\n",
    "    text = [word.lower() for word in text]\n",
    "    return \" \".join(text)\n",
    "\n",
    "def removing_punctuations(text):\n",
    "    \"\"\"Remove punctuations from the text.\"\"\"\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), ' ', text)\n",
    "    text = text.replace('ÿõ', \"\")\n",
    "    text = re.sub('\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def removing_urls(text):\n",
    "    \"\"\"Remove URLs from the text.\"\"\"\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r'', text)\n",
    "\n",
    "# applying all of these functions to our data --> df \n",
    "def normalize_text(df):\n",
    "    \"\"\"Normalize the text data.\"\"\"\n",
    "    try:\n",
    "        df['review'] = df['review'].apply(lower_case)\n",
    "        df['review'] = df['review'].apply(remove_stop_words)\n",
    "        df['review'] = df['review'].apply(removing_numbers)\n",
    "        df['review'] = df['review'].apply(removing_punctuations)\n",
    "        df['review'] = df['review'].apply(removing_urls)\n",
    "        df['review'] = df['review'].apply(lemmatization)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f'Error during text normalization: {e}')\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>love umberto lenzi s cop movie rome armed teet...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>oh lord thinking one frantically unfunny worse...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>emma horribly flawed film based jane austen cl...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>year watched movie many time seeing hbo copy d...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>understand low rating film delight people like...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                review sentiment\n",
       "243  love umberto lenzi s cop movie rome armed teet...  negative\n",
       "955  oh lord thinking one frantically unfunny worse...  negative\n",
       "596  emma horribly flawed film based jane austen cl...  positive\n",
       "777  year watched movie many time seeing hbo copy d...  positive\n",
       "709  understand low rating film delight people like...  positive"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = normalize_text(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "negative    257\n",
       "positive    243\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['sentiment'].isin(['positive','negative'])\n",
    "df = df[x]\n",
    "# it will remove the neutral reviews or any other reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>love umberto lenzi s cop movie rome armed teet...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>oh lord thinking one frantically unfunny worse...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>emma horribly flawed film based jane austen cl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>year watched movie many time seeing hbo copy d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>understand low rating film delight people like...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                review  sentiment\n",
       "243  love umberto lenzi s cop movie rome armed teet...          0\n",
       "955  oh lord thinking one frantically unfunny worse...          0\n",
       "596  emma horribly flawed film based jane austen cl...          1\n",
       "777  year watched movie many time seeing hbo copy d...          1\n",
       "709  understand low rating film delight people like...          1"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'] = df['sentiment'].map({'positive':1, 'negative':0})\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review       0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_features=50)\n",
    "X = vectorizer.fit_transform(df['review'])\n",
    "y = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"Manav54321/MLOps_capstone\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"Manav54321/MLOps_capstone\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-19 15:27:38,036 - INFO - Initialized MLflow to track repo \"Manav54321/MLOps_capstone\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository Manav54321/MLOps_capstone initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository Manav54321/MLOps_capstone initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-19 15:27:38,038 - INFO - Repository Manav54321/MLOps_capstone initialized!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/be1f6338b3b3468eb1da856dd2266a09', creation_time=1744878744632, experiment_id='0', last_update_time=1744878744632, lifecycle_stage='active', name='Logistic Regression Baseline', tags={}>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dagshub\n",
    "\n",
    "mlflow.set_tracking_uri('https://dagshub.com/Manav54321/MLOps_capstone.mlflow')\n",
    "dagshub.init(repo_owner='Manav54321', repo_name='MLOps_capstone', mlflow=True)\n",
    "\n",
    "# mlflow.set_experiment(\"Logistic Regression Baseline\")\n",
    "mlflow.set_experiment(\"Logistic Regression Baseline\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-19 15:27:42,124 - INFO - Starting MLflow run...\n",
      "2025-04-19 15:27:42,670 - INFO - Logging preprocessing parameters...\n",
      "2025-04-19 15:27:45,303 - INFO - Initializing Logistic Regression model...\n",
      "2025-04-19 15:27:45,307 - INFO - Fitting the model...\n",
      "2025-04-19 15:27:45,326 - INFO - Model training complete.\n",
      "2025-04-19 15:27:45,327 - INFO - Logging model parameters...\n",
      "2025-04-19 15:27:46,018 - INFO - Making predictions...\n",
      "2025-04-19 15:27:46,021 - INFO - Calculating evaluation metrics...\n",
      "2025-04-19 15:27:46,031 - INFO - Logging evaluation metrics...\n",
      "2025-04-19 15:27:48,341 - INFO - Saving and logging the model...\n",
      "2025-04-19 15:27:48,352 - ERROR - An error occurred: cannot import name '_load_context_model_and_signature' from 'mlflow.pyfunc.model' (/opt/anaconda3/envs/atlas/lib/python3.10/site-packages/mlflow/pyfunc/model.py)\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/96/8d_2l3_j2vn7zbh4q2tkhxbm0000gn/T/ipykernel_59370/3375003421.py\", line 48, in <module>\n",
      "    mlflow.sklearn.log_model(model, \"model\")\n",
      "  File \"/opt/anaconda3/envs/atlas/lib/python3.10/site-packages/mlflow/sklearn/__init__.py\", line 413, in log_model\n",
      "    return Model.log(\n",
      "  File \"/opt/anaconda3/envs/atlas/lib/python3.10/site-packages/mlflow/models/model.py\", line 855, in log\n",
      "    flavor.save_model(path=local_path, mlflow_model=mlflow_model, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/atlas/lib/python3.10/site-packages/mlflow/sklearn/__init__.py\", line 274, in save_model\n",
      "    pyfunc.add_to_model(\n",
      "  File \"/opt/anaconda3/envs/atlas/lib/python3.10/site-packages/mlflow/utils/lazy_load.py\", line 41, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"/opt/anaconda3/envs/atlas/lib/python3.10/site-packages/mlflow/utils/lazy_load.py\", line 30, in _load\n",
      "    module = importlib.import_module(self.__name__)\n",
      "  File \"/opt/anaconda3/envs/atlas/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/opt/anaconda3/envs/atlas/lib/python3.10/site-packages/mlflow/pyfunc/__init__.py\", line 427, in <module>\n",
      "    import mlflow.pyfunc.loaders\n",
      "  File \"/opt/anaconda3/envs/atlas/lib/python3.10/site-packages/mlflow/pyfunc/loaders/__init__.py\", line 1, in <module>\n",
      "    import mlflow.pyfunc.loaders.chat_agent\n",
      "  File \"/opt/anaconda3/envs/atlas/lib/python3.10/site-packages/mlflow/pyfunc/loaders/chat_agent.py\", line 8, in <module>\n",
      "    from mlflow.pyfunc.model import (\n",
      "ImportError: cannot import name '_load_context_model_and_signature' from 'mlflow.pyfunc.model' (/opt/anaconda3/envs/atlas/lib/python3.10/site-packages/mlflow/pyfunc/model.py)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run placid-ram-832 at: https://dagshub.com/Manav54321/MLOps_capstone.mlflow/#/experiments/0/runs/9985d1c1eb5b4683b0f550949f7331ff\n",
      "üß™ View experiment at: https://dagshub.com/Manav54321/MLOps_capstone.mlflow/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import logging\n",
    "import os\n",
    "import time \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "logging.info(\"Starting MLflow run...\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        logging.info(\"Logging preprocessing parameters...\")\n",
    "        mlflow.log_param(\"vectorizer\", \"Bag of Words\")\n",
    "        mlflow.log_param(\"num_features\", 50)\n",
    "        mlflow.log_param(\"test_size\", 0.20)\n",
    "\n",
    "        logging.info(\"Initializing Logistic Regression model...\")\n",
    "        model = LogisticRegression(max_iter=1000)  # Increase max_iter to prevent non-convergence issues\n",
    "\n",
    "        logging.info(\"Fitting the model...\")\n",
    "        model.fit(X_train, y_train)\n",
    "        logging.info(\"Model training complete.\")\n",
    "\n",
    "        logging.info(\"Logging model parameters...\")\n",
    "        mlflow.log_param(\"model\", \"Logistic Regression\")\n",
    "\n",
    "        logging.info(\"Making predictions...\")\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        logging.info(\"Calculating evaluation metrics...\")\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "        logging.info(\"Logging evaluation metrics...\")\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "\n",
    "        logging.info(\"Saving and logging the model...\")\n",
    "        mlflow.sklearn.log_model(model, \"model\")\n",
    "\n",
    "        # Log execution time\n",
    "        end_time = time.time()\n",
    "        logging.info(f\"Model training and logging completed in {end_time - start_time:.2f} seconds.\")\n",
    "\n",
    "        # Save and log the notebook\n",
    "        # notebook_path = \"exp1_baseline_model.ipynb\"\n",
    "        # logging.info(\"Executing Jupyter Notebook. This may take a while...\")\n",
    "        # os.system(f\"jupyter nbconvert --to notebook --execute --inplace {notebook_path}\")\n",
    "        # mlflow.log_artifact(notebook_path)\n",
    "\n",
    "        # logging.info(\"Notebook execution and logging complete.\")\n",
    "\n",
    "        # Print the results for verification\n",
    "        logging.info(f\"Accuracy: {accuracy}\")\n",
    "        logging.info(f\"Precision: {precision}\")\n",
    "        logging.info(f\"Recall: {recall}\")\n",
    "        logging.info(f\"F1 Score: {f1}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred: {e}\", exc_info=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atlas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
